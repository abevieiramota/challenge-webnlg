{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.sys.path.insert(0, '../script')\n",
    "\n",
    "from reading_thiagos_templates import read_thiagos_xml_entries, make_template, get_lexicalizations\n",
    "from collections import ChainMap, defaultdict, Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob('../../webnlg/data/delexicalized/v1.4/train/**/*.xml', recursive=True)\n",
    "filepaths.extend(glob.glob('../../webnlg/data/delexicalized/v1.4/dev/**/*.xml', recursive=True))\n",
    "\n",
    "template_db = defaultdict(Counter)\n",
    "lexicalization_db = defaultdict(Counter)\n",
    "\n",
    "failed_lexicalizations = defaultdict(list)\n",
    "\n",
    "for filepath in filepaths:\n",
    "    \n",
    "    entries = read_thiagos_xml_entries(filepath)\n",
    "    \n",
    "    for entry in entries:\n",
    "        \n",
    "        for lexe in entry['lexes']:\n",
    "            \n",
    "            if lexe['comment'] == 'good':\n",
    "                \n",
    "                if entry['entity_map']:\n",
    "            \n",
    "                    try:\n",
    "                        t = make_template(entry['triples'], \n",
    "                                          lexe['text'], \n",
    "                                          lexe['template'], \n",
    "                                          entry['r_entity_map'], \n",
    "                                          metadata={'filepath': filepath})\n",
    "                        template_db[t.structure][t] += 1\n",
    "                    except Exception as ex:\n",
    "                        if str(ex) in ['triples must contain only one root', 'structure and template_text must match slots']:\n",
    "                            continue\n",
    "                        raise ex\n",
    "\n",
    "                    lexicals = get_lexicalizations(lexe['text'], lexe['template'], entry['entity_map'])\n",
    "                    \n",
    "                    if lexicals:\n",
    "\n",
    "                        for lex_key, lex_value in lexicals.items():\n",
    "\n",
    "                            lexicalization_db[lex_key].update(lex_value)\n",
    "                    else:\n",
    "                        failed_lexicalizations[filepath].append(entry)\n",
    "\n",
    "                        \n",
    "template_db = dict(template_db)\n",
    "lexicalization_db = dict(lexicalization_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{AGENT-1} is located in {BRIDGE-1}, {PATIENT-1} and the language is {PATIENT-2}. 1\n",
      "{PATIENT-2} is the language of {BRIDGE-1} where {AGENT-1} is located and the capital city is {PATIENT-1}. 1\n",
      "{AGENT-1} is located in {BRIDGE-1} which has the capital city of {PATIENT-1}. The language spoken in {BRIDGE-1} is {PATIENT-2}. 1\n",
      "{AGENT-1} is from {BRIDGE-1}, where the capital is {PATIENT-1} and {PATIENT-2} is the language . 1\n",
      "{AGENT-1} can be found in {BRIDGE-1} which has the capital city of {PATIENT-1} and uses {PATIENT-2}. 1\n",
      "{BRIDGE-1} is home to {PATIENT-2}, the capital {PATIENT-1} and {AGENT-1}. 1\n"
     ]
    }
   ],
   "source": [
    "from template_based import *\n",
    "\n",
    "triples = [{'subject': 'AGENT-1', 'predicate': 'country', 'object': 'BRIDGE-1'},\n",
    "           {'subject': 'BRIDGE-1', 'predicate': 'capital', 'object': 'PATIENT-1'},\n",
    "           {'subject': 'BRIDGE-1', 'predicate': 'language', 'object': 'PATIENT-2'}]\n",
    "\n",
    "templates = template_db[Structure.from_triples(triples)]\n",
    "\n",
    "for template, count in templates.most_common():\n",
    "    \n",
    "    print(template.template_text, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Alcatraz Versus the Evil Librarians': 69,\n",
       "         'Alcatrz Versus the Evil Librarians': 1,\n",
       "         'Alcatraz Versus The Evil Librarian': 3,\n",
       "         'Alcatraz versus the Evil Librarians': 2,\n",
       "         'The book Alcatraz Versus the Evil Librarians': 20,\n",
       "         \"The book 'Alcatraz Versus the Evil Librarian'\": 1,\n",
       "         'its': 2,\n",
       "         'the book Alcatraz Versus the Evil Librarians': 7,\n",
       "         'it': 4,\n",
       "         'Alcatraz versus the Evil LIbrarians': 1,\n",
       "         'Alcatraz Versus the Evil Libraries': 1,\n",
       "         'The book': 3,\n",
       "         'Alcatraz Versus the Evil Librarian': 1,\n",
       "         'D.C. Alcatraz Versus the Evil Librarians': 1,\n",
       "         'a book Alcatraz Versus the Evil Librarians': 1,\n",
       "         'This book': 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicalization_db['Alcatraz_Versus_the_Evil_Librarians']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('thiago_template_db', 'wb') as f:\n",
    "    pickle.dump(template_db, f)\n",
    "    \n",
    "with open('thiago_lexicalization_db', 'wb') as f:\n",
    "    pickle.dump(lexicalization_db, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "template_db = None\n",
    "with open('thiago_template_db', 'rb') as f:\n",
    "    template_db = pickle.load(f)\n",
    "    \n",
    "template_enhanced_db = defaultdict(Counter)\n",
    "template_enhanced_db.update(template_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from template_based import *\n",
    "\n",
    "RE_REMOVE_FINAL_DOT = re.compile(r'\\.$')\n",
    "# assumes the sentence is in active voice\n",
    "RE_REMOVE_AGENT_1 = re.compile(r'^.*?{AGENT-1}')\n",
    "\n",
    "def make_text(t1, t2):\n",
    "    \n",
    "    t1_ = RE_REMOVE_FINAL_DOT.sub('', t1)\n",
    "    \n",
    "    t2_ = RE_REMOVE_AGENT_1.sub('', t2).replace('{PATIENT-1}', '{PATIENT-2}')\n",
    "    \n",
    "    return '{} and {}'.format(t1_, t2_)\n",
    "\n",
    "def make_structure(h1, h2):\n",
    "    \n",
    "    o1 = Slot('PATIENT-1', [])\n",
    "    p1 = Predicate(h1.predicates[0].value, [o1])\n",
    "    o2 = Slot('PATIENT-2', [])\n",
    "    p2 = Predicate(h2.predicates[0].value, [o2])\n",
    "    \n",
    "    s = Slot('AGENT-1', [p1, p2])\n",
    "    \n",
    "    return Structure(s)\n",
    "\n",
    "def make_new_template(t1, t2):\n",
    "    \n",
    "    template_text = make_text(t1.template_text, t2.template_text)\n",
    "    structure = make_structure(t1.structure.head, t2.structure.head)\n",
    "    \n",
    "    return Template(structure, template_text, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "templates_w_1_size = [t for s, t in template_db.items() if len(s) == 1]\n",
    "\n",
    "#probably passive voice\n",
    "w_error = []\n",
    "\n",
    "for t1_c, t2_c in combinations(templates_w_1_size, 2):\n",
    "    \n",
    "    t1 = t1_c.most_common(1)[0][0]\n",
    "    t2 = t2_c.most_common(1)[0][0]\n",
    "    \n",
    "    try:\n",
    "        t12 = make_new_template(t1, t2)\n",
    "        template_enhanced_db[t12.structure][t12] +=1\n",
    "    except:\n",
    "        w_error.append((t1, t2))\n",
    "    \n",
    "    try:\n",
    "        t21 = make_new_template(t2, t1)\n",
    "        template_enhanced_db[t21.structure][t21] +=1\n",
    "    except:\n",
    "        w_error.append((t2, t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('thiago_enhanced_template_db', 'wb') as f:\n",
    "    pickle.dump(dict(template_enhanced_db), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
