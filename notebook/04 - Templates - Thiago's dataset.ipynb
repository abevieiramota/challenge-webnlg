{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.sys.path.insert(0, '../script')\n",
    "\n",
    "from reading_thiagos_templates import read_thiagos_xml_entries, make_template, get_lexicalizations\n",
    "from collections import ChainMap, defaultdict, Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob('../../webnlg/data/delexicalized/v1.4/train/**/*.xml', recursive=True)\n",
    "filepaths.extend(glob.glob('../../webnlg/data/delexicalized/v1.4/dev/**/*.xml', recursive=True))\n",
    "\n",
    "template_db = defaultdict(Counter)\n",
    "lexicalization_db = defaultdict(Counter)\n",
    "\n",
    "failed_lexicalizations = defaultdict(list)\n",
    "\n",
    "for filepath in filepaths:\n",
    "    \n",
    "    entries = read_thiagos_xml_entries(filepath)\n",
    "    \n",
    "    for entry in entries:\n",
    "        \n",
    "        for lexe in entry['lexes']:\n",
    "            \n",
    "            if lexe['comment'] == 'good':\n",
    "                \n",
    "                if entry['entity_map']:\n",
    "            \n",
    "                    try:\n",
    "                        t = make_template(entry['triples'], \n",
    "                                          lexe['text'], \n",
    "                                          lexe['template'], \n",
    "                                          entry['r_entity_map'], \n",
    "                                          metadata={'filepath': filepath})\n",
    "                        template_db[t.structure][t] += 1\n",
    "                    except Exception as ex:\n",
    "                        if str(ex) in ['triples must contain only one root', 'structure and template_text must match slots']:\n",
    "                            continue\n",
    "                        raise ex\n",
    "\n",
    "                    lexicals = get_lexicalizations(lexe['text'], lexe['template'], entry['entity_map'])\n",
    "                    \n",
    "                    if lexicals:\n",
    "\n",
    "                        for lex_key, lex_value in lexicals.items():\n",
    "\n",
    "                            lexicalization_db[lex_key].update(lex_value)\n",
    "                    else:\n",
    "                        failed_lexicalizations[filepath].append(entry)\n",
    "\n",
    "                        \n",
    "template_db = dict(template_db)\n",
    "lexicalization_db = dict(lexicalization_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{AGENT-1} is located in {BRIDGE-1}, {PATIENT-1} and the language is {PATIENT-2}. 1\n",
      "{PATIENT-2} is the language of {BRIDGE-1} where {AGENT-1} is located and the capital city is {PATIENT-1}. 1\n",
      "{AGENT-1} is located in {BRIDGE-1} which has the capital city of {PATIENT-1}. The language spoken in {BRIDGE-1} is {PATIENT-2}. 1\n",
      "{AGENT-1} is from {BRIDGE-1}, where the capital is {PATIENT-1} and {PATIENT-2} is the language . 1\n",
      "{AGENT-1} can be found in {BRIDGE-1} which has the capital city of {PATIENT-1} and uses {PATIENT-2}. 1\n",
      "{BRIDGE-1} is home to {PATIENT-2}, the capital {PATIENT-1} and {AGENT-1}. 1\n"
     ]
    }
   ],
   "source": [
    "from template_based import Structure\n",
    "\n",
    "triples = [{'subject': 'AGENT-1', 'predicate': 'country', 'object': 'BRIDGE-1'},\n",
    "           {'subject': 'BRIDGE-1', 'predicate': 'capital', 'object': 'PATIENT-1'},\n",
    "           {'subject': 'BRIDGE-1', 'predicate': 'language', 'object': 'PATIENT-2'}]\n",
    "\n",
    "templates = template_db[Structure.from_triples(triples)]\n",
    "\n",
    "for template, count in templates.most_common():\n",
    "    \n",
    "    print(template.template_text, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Alcatraz Versus the Evil Librarians': 69,\n",
       "         'Alcatrz Versus the Evil Librarians': 1,\n",
       "         'Alcatraz Versus The Evil Librarian': 3,\n",
       "         'Alcatraz versus the Evil Librarians': 2,\n",
       "         'The book Alcatraz Versus the Evil Librarians': 20,\n",
       "         \"The book 'Alcatraz Versus the Evil Librarian'\": 1,\n",
       "         'its': 2,\n",
       "         'the book Alcatraz Versus the Evil Librarians': 7,\n",
       "         'it': 4,\n",
       "         'Alcatraz versus the Evil LIbrarians': 1,\n",
       "         'Alcatraz Versus the Evil Libraries': 1,\n",
       "         'The book': 3,\n",
       "         'Alcatraz Versus the Evil Librarian': 1,\n",
       "         'D.C. Alcatraz Versus the Evil Librarians': 1,\n",
       "         'a book Alcatraz Versus the Evil Librarians': 1,\n",
       "         'This book': 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicalization_db['Alcatraz_Versus_the_Evil_Librarians']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('thiago_template_db', 'wb') as f:\n",
    "    pickle.dump(template_db, f)\n",
    "    \n",
    "with open('thiago_lexicalization_db', 'wb') as f:\n",
    "    pickle.dump(lexicalization_db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "template_db = None\n",
    "with open('thiago_template_db', 'rb') as f:\n",
    "    template_db = pickle.load(f)\n",
    "    \n",
    "lexicalization_db = None\n",
    "with open('thiago_lexicalization_db', 'rb') as f:\n",
    "    lexicalization_db = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
