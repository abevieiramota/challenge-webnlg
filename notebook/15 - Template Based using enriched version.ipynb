{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \u001b[93mInfo about spaCy\u001b[0m\n",
      "\n",
      "    spaCy version      2.0.16         \n",
      "    Location           /home/abevieiramota/anaconda3/envs/webnlg/lib/python3.6/site-packages/spacy\n",
      "    Platform           Linux-4.4.0-43-Microsoft-x86_64-with-debian-stretch-sid\n",
      "    Python version     3.6.7          \n",
      "    Models             en, en_core_web_lg\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spaCy version': '2.0.16',\n",
       " 'Location': '/home/abevieiramota/anaconda3/envs/webnlg/lib/python3.6/site-packages/spacy',\n",
       " 'Platform': 'Linux-4.4.0-43-Microsoft-x86_64-with-debian-stretch-sid',\n",
       " 'Python version': '3.6.7',\n",
       " 'Models': 'en, en_core_web_lg'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from textacy import extract\n",
    "\n",
    "spacy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.insert(0, '../script')\n",
    "from webnlg import *\n",
    "from evaluation import *\n",
    "from lexicalization import *\n",
    "from sentence_generation import *\n",
    "from content_selection import SelectAllContentSelection\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import groupby, islice\n",
    "from template_extraction import *\n",
    "from discourse_structuring import *\n",
    "from sentence_aggregation import *\n",
    "from text_generation import TemplateBasedTextGenerator\n",
    "import networkx.algorithms.isomorphism as iso\n",
    "from data_alignment import *\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from textacy import similarity\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import webnlg\n",
    "reload(webnlg)\n",
    "from webnlg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_12 = WebNLGCorpus.load(['dev_1.2', 'train_1.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7812/7812 [02:04<00:00, 62.51it/s] \n"
     ]
    }
   ],
   "source": [
    "EDGE_MATCH = iso.categorical_edge_match(['predicate', 's_label', 'o_label'], [None, None, None])\n",
    "\n",
    "def get_templates_counter(graph):\n",
    "    \n",
    "    n_triplas = len(graph.edges())\n",
    "    \n",
    "    for g, templates_counter in template_db[n_triplas].items():\n",
    "        \n",
    "        if nx.is_isomorphic(graph, g, edge_match=EDGE_MATCH):\n",
    "            \n",
    "            return g, templates_counter\n",
    "    return None, None\n",
    "\n",
    "\n",
    "replace_agent_bridge_patient_slot = re.compile(r'((AGENT-\\d)|(BRIDGE-\\d)|(PATIENT-\\d))')\n",
    "\n",
    "template_db = {x: defaultdict(Counter) for x in range(1, 8)}\n",
    "\n",
    "for e in tqdm(v_12):\n",
    "    \n",
    "    delex_graph = e.get_graph(delexicalized=True)\n",
    "    if delex_graph:\n",
    "    \n",
    "        iso_g, _ = get_templates_counter(e.get_graph())\n",
    "\n",
    "        if iso_g is None:\n",
    "            iso_g = delex_graph\n",
    "\n",
    "        n_triplas = len(e.get_data())\n",
    "\n",
    "        for lexe in e.entry['lexes']:\n",
    "\n",
    "            template = Template(replace_agent_bridge_patient_slot.sub('{\\g<1>}', lexe['template']))\n",
    "\n",
    "            template_db[n_triplas][iso_g][template] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content selection\n",
    "cs = SelectAllContentSelection()\n",
    "\n",
    "# sentence generation\n",
    "t = ManualTemplateExtract()\n",
    "v_12_ntriples_1 = v_12.subset(ntriples=1)\n",
    "template_db_ = t.extract(v_12_ntriples_1)\n",
    "\n",
    "mfe = MostFrequentTemplateSentenceGenerator()\n",
    "mfe.fit(template_db_)\n",
    "\n",
    "npsg = NearestPredicateTemplateSentenceGenerator(sentence_generator=mfe,\n",
    "                                                 similarity_metric=similarity.jaro_winkler,\n",
    "                                                 threshold=0.8)\n",
    "npsg.fit(template_db_)\n",
    "\n",
    "fsg = FallBackPipelineSentenceGenerator([mfe, npsg, JustJoinTripleSentenceGenerator()])\n",
    "\n",
    "\n",
    "# lexicalization\n",
    "la = LexicalizeAsAligned()\n",
    "la.fit(v_12_ntriples_1)\n",
    "\n",
    "# discourse structuring\n",
    "ds = DoesntSortDiscourseStructuring()\n",
    "\n",
    "# sentence aggregation\n",
    "sa = OneSentenceAggregator()\n",
    "\n",
    "nlg = TemplateBasedTextGenerator(cs, fsg, la, ds, sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = WebNLGCorpus.load(\"test_with_lex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbalize(graph):\n",
    "    \n",
    "    g_iso, templates_counter = get_templates_counter(graph)\n",
    "    \n",
    "    if not g_iso:\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    #TODO: improve get_templates para já retornar o mapeamento\n",
    "    GM = nx.algorithms.isomorphism.DiGraphMatcher(g_iso, graph)\n",
    "    \n",
    "    mapping = next(GM.isomorphisms_iter())\n",
    "    \n",
    "    mapping_ = []\n",
    "    \n",
    "    for k, v in mapping.items():\n",
    "        \n",
    "        if v in la.subject_lexicalization:\n",
    "            mapping_.append((k, la.subject_lexicalization[v].most_common(1)[0][0]))\n",
    "        elif v in la.object_lexicalization:\n",
    "            mapping_.append((k, la.object_lexicalization[v].most_common(1)[0][0]))\n",
    "        else:\n",
    "            mapping_.append((k, preprocess_so(v)))\n",
    "            \n",
    "    mapping = dict(mapping_)\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    for template, n in templates_counter.most_common():\n",
    "        \n",
    "        texts.append((template.fill(mapping), n))\n",
    "        \n",
    "    return texts\n",
    "\n",
    "# https://stackoverflow.com/a/30134039/3662965\n",
    "def partition(collection):\n",
    "    if len(collection) == 1:\n",
    "        yield [ collection ]\n",
    "        return\n",
    "\n",
    "    first = collection[0]\n",
    "    for smaller in partition(collection[1:]):\n",
    "        # insert `first` in each of the subpartition's subsets\n",
    "        for n, subset in enumerate(smaller):\n",
    "            yield smaller[:n] + [[ first ] + subset]  + smaller[n+1:]\n",
    "        # put `first` in its own subset \n",
    "        yield [ [ first ] ] + smaller\n",
    "\n",
    "\n",
    "def templates(s):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    last_i = 0\n",
    "    \n",
    "    data = s.get_data()\n",
    "    \n",
    "    while len(data) > 0:\n",
    "        \n",
    "        found = False\n",
    "        \n",
    "        for i in range(len(data), last_i, -1):\n",
    "            \n",
    "            g = get_graph_from_triples(data[:i])\n",
    "            \n",
    "            ts = verbalize(g)\n",
    "            \n",
    "            if ts:\n",
    "                \n",
    "                result.append(ts[0][0])\n",
    "                data = data[i:]\n",
    "                last_i = i\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            return result, data\n",
    "                \n",
    "    return result, None\n",
    "\n",
    "def templates2(s):\n",
    "    \n",
    "    for p in partition(s.get_data()):\n",
    "        \n",
    "        texts = []\n",
    "        \n",
    "        shit = False\n",
    "        \n",
    "        for p_ in p:\n",
    "            \n",
    "            g = get_graph_from_triples(p_)\n",
    "            \n",
    "            ts = verbalize(g)\n",
    "            \n",
    "            if not ts:\n",
    "                \n",
    "                shit = True\n",
    "                break\n",
    "            else:\n",
    "                texts.append(ts[0][0])\n",
    "                \n",
    "        if not shit:\n",
    "            return texts, None\n",
    "        \n",
    "    return None, s.get_data()\n",
    "\n",
    "\n",
    "def generate(e):\n",
    "    \n",
    "    result, data = templates2(e)\n",
    "    \n",
    "    texts = []\n",
    "    if result:\n",
    "\n",
    "        texts.append('.'.join(result))\n",
    "\n",
    "    if data:\n",
    "        texts.append(nlg.predict_entry(data))\n",
    "        \n",
    "    return ' '.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = [] \n",
    "\n",
    "for e in test:\n",
    "\n",
    "    generated.append(generate(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "with codecs.open('../data/models/elmodel3.txt', 'w', 'utf-8') as f:\n",
    "    \n",
    "    for text in generated:\n",
    "        \n",
    "        f.write(\"{}\\n\".format(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files creating finished for:  elmodel3\r\n"
     ]
    }
   ],
   "source": [
    "!python ../evaluation/webnlg2017/webnlg-automatic-evaluation-v2/evaluation_v2.py --team_name elmodel3 --team_filepath ../data/models/elmodel3.txt --outdir ../tmp/elmodel3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 40.95, 'meteor': 0.3844564946198066, 'ter': 0.5489830867214401}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_all_cat = \"../tmp/elmodel3/elmodel3_all-cat.txt\"\n",
    "\n",
    "evaluate_texts(bleu_all_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 42.27, 'meteor': 0.38013555867054244, 'ter': 0.532704777664466}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_all_cat = \"../tmp/elmodel/elmodel_all-cat.txt\"\n",
    "\n",
    "evaluate_texts(bleu_all_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 44.01, 'meteor': 0.3909775015368552, 'ter': 0.5066825729733884}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(nlg, 'ola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({{subject} was created by {object} .: 58,\n",
       "         The creator of {subject} is {object} .: 13,\n",
       "         {subject} , was created by {object} .: 3,\n",
       "         {object} created {subject} .: 8,\n",
       "         {object} is one of the creators of {subject} .: 1,\n",
       "         {object} is the creator of {subject} .: 13,\n",
       "         {subject} were created by {object} .: 1,\n",
       "         {subject} is created by {object} .: 2,\n",
       "         {subject} is a fictional character created by {object} .: 1,\n",
       "         {object} was the creator of {subject} .: 3,\n",
       "         {object} was one of the creators of {subject} .: 1,\n",
       "         {subject} was created by {object} in the comics genre .: 1,\n",
       "         {subject} is a comic character created by {object} .: 1,\n",
       "         {subject} , The Arrow , was created by {object} .: 1,\n",
       "         {subject} was created at {object} .: 1,\n",
       "         {subject} was created in {object} .: 1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_db['creator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = WebNLGCorpus.load(['test_with_lex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Triple info: category=Building eid=Id471\n",
       "\n",
       "\tModified triples:\n",
       "\n",
       "Alan_B._Miller_Hall | buildingStartDate | \"30 March 2007\"\n",
       "Mason_School_of_Business | country | United_States\n",
       "Alan_B._Miller_Hall | currentTenants | Mason_School_of_Business\n",
       "\n",
       "\n",
       "\tLexicalizations:\n",
       "\n",
       "Alan B. Miller Hall was started on March 30,2007 and has The Mason School of Business in the U.S. as a tenant. || \n",
       "Alan B. Miller Hall's building opened in 30th March 2007. The Mason School of Business in the United States are the current tenants of Alan B Miller Hall. || "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = test.sample(ntriples=3)\n",
    "\n",
    "text = nlg.predict_entry(sample.get_data())\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The construction of alan b miller hall began in 30th march 2007 . the mason school of business is in the united states . the mason school of business are the current tenants of alan b miller hall .'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Triple info: category=SportsTeam eid=Id125\n",
       "\n",
       "\tModified triples:\n",
       "\n",
       "Michele_Marcolini | club | Atalanta_B.C.\n",
       "\n",
       "\n",
       "\tLexicalizations:\n",
       "\n",
       "Michele Marcolini has played for Atalanta BC. || \n",
       "Michele Marcolini is part of the Atalanta B.C. club. || \n",
       "Michele Marcolini plays for Atalanta B.C. || "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = test.sample()\n",
    "\n",
    "text = nlg.predict_entry(sample.get_data())\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'michele marcolini plays for Atalanta B.C. .'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
