{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gets notebook name and commit hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_name = nb_name.rsplit('.')[0]\n",
    "\n",
    "commit = !git rev-parse HEAD\n",
    "commit = commit[0]\n",
    "\n",
    "model_name = \"{}_{}\".format(nb_name, commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"{}.txt\".format(model_name)\n",
    "log_filename = \"{}.log\".format(model_name)\n",
    "\n",
    "import os\n",
    "\n",
    "output_filepath = os.path.join('../data/models', output_filename)\n",
    "log_filepath = os.path.join('../data/models', log_filename)\n",
    "\n",
    "model_temp_dir = os.path.join('../tmp/', model_name)\n",
    "\n",
    "bleu_all_cat = os.path.join(model_temp_dir, \"{}_all-cat.txt\".format(model_name))\n",
    "\n",
    "if not os.path.isdir(model_temp_dir):\n",
    "    os.mkdir(model_temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logs to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=log_filepath, \n",
    "                    level=logging.DEBUG, \n",
    "                    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's generate the template based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../script/webnlg.py\n",
    "%run ../script/data_alignment.py\n",
    "\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateExtractionModel:\n",
    "    \n",
    "    def __init__(self, data_alignment_model):\n",
    "    \n",
    "        self.data_alignment_model = data_alignment_model\n",
    "        \n",
    "\n",
    "    def extract_template(self, text, data):\n",
    "\n",
    "        # spacy model\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # TODO: monitor success of subj/obje alignment\n",
    "        m_subject_span, m_object_span = self.data_alignment_model.align_data(doc, data)\n",
    "\n",
    "        # breaks text into char array\n",
    "        text_char = list(text)\n",
    "\n",
    "        # replaces subject text with m_subject placeholder\n",
    "        text_char[m_subject_span.start_char: m_subject_span.end_char] = '{m_subject}'\n",
    "\n",
    "        if m_object_span:\n",
    "            # tests if the object occurs after the subject >\n",
    "            #    if it is the case, you have to adjust the indexes accordingly\n",
    "            if m_subject_span.start_char > m_object_span.end_char:\n",
    "\n",
    "                base = 0\n",
    "            else:\n",
    "                # adjustes the indexes\n",
    "                # length of the extracted subject text\n",
    "                len_subject_text = m_subject_span.end_char - m_subject_span.start_char\n",
    "                # length of the placeholder minus len_subject_text\n",
    "                base = len('{m_subject}') - len_subject_text\n",
    "\n",
    "            # replaces object text with m_object placeholder\n",
    "            text_char[base + m_object_span.start_char: base + m_object_span.end_char] = '{m_object}'\n",
    "\n",
    "        # build template using the char array\n",
    "        return ''.join(text_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebNLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = WebNLGCorpus.load('train')\n",
    "dev = WebNLGCorpus.load('dev')\n",
    "\n",
    "# BIAS: use only 1 tripleset size dataset\n",
    "train_1 = train.subset(ntriples=1)\n",
    "dev_1 = dev.subset(ntriples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how many m_predicates exists in train and not in train_1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5th_runway_SurfaceType',\n",
       " 'affiliations',\n",
       " 'architecture',\n",
       " 'broadcastedBy',\n",
       " 'campus',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'firstAired',\n",
       " 'gemstone',\n",
       " 'has to its northwest',\n",
       " 'has to its southeast',\n",
       " 'mascot',\n",
       " 'neighboringMunicipality',\n",
       " 'numberOfRooms',\n",
       " 'patronSaint',\n",
       " 'protein',\n",
       " 'series',\n",
       " 'served',\n",
       " 'servingSize'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_train_ni_train_1 = set(train.mdf.m_predicate.unique()).difference(train_1.mdf.m_predicate.unique())\n",
    "in_train_ni_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    The Faroese language\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">m_object: : Faroese language</span>\n",
       "</mark>\n",
       " is spoken in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Denmark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">m_subject: Denmark</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample an entry\n",
    "e = train_1.sample(idx='0_210')\n",
    "\n",
    "# data alignment model with token_sort_ratio similarity metric\n",
    "# PARAM/BIAS: similarity_metric \n",
    "# TODO: train changing similarity_metric\n",
    "da = RootDataAlignmentModel(similarity.token_sort_ratio)\n",
    "# template extraction model\n",
    "te = TemplateExtractionModel(da)\n",
    "    \n",
    "# uses the first reference text\n",
    "# it can have more than 1 reference text\n",
    "first_lexicalization = e.ldf.ltext.values.tolist()[0]\n",
    "# uses the first triple\n",
    "first_triple = e.preprocessed_so()[0]\n",
    "\n",
    "da.render_aligned(nlp(first_lexicalization), first_triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'language'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.mdf.m_predicate.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{m_object} is spoken in {m_subject}.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracts the template\n",
    "template = te.extract_template(first_lexicalization, first_triple)\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Portuguese is spoken in Brazil.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.format(**{'m_subject': 'Brazil', 'm_object': 'Portuguese'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{m_subject} picks up the {m_object} in the church\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Abelardo Vieira Mota picks up the car in the church'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: remove lexicalized information not present in data\n",
    "text = 'Eleanor Rigby picks up the rice in the church'\n",
    "data = {'m_subject': 'Eleanor Rigby', \n",
    "        'm_object': 'rice'}\n",
    "\n",
    "da = RootDataAlignmentModel(similarity.token_sort_ratio)\n",
    "te = TemplateExtractionModel(da)\n",
    "\n",
    "template = te.extract_template(text, data)\n",
    "\n",
    "print(template)\n",
    "\n",
    "template.format(**{'m_subject': 'Abelardo Vieira Mota', 'm_object': 'car'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 32s, sys: 3.11 s, total: 3min 35s\n",
      "Wall time: 59.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "da = RootDataAlignmentModel(similarity.token_sort_ratio)\n",
    "te = TemplateExtractionModel(da)\n",
    "\n",
    "template_db = defaultdict(list)\n",
    "\n",
    "#! BIAS: using only train_1 sentences\n",
    "# for each sentence, extracts template\n",
    "for entry in chain(train_1, dev_1):\n",
    "    \n",
    "    for text in entry.ldf.ltext.tolist():\n",
    "        # to dictionary of s, o; [0] because to_dict returns a list of dicts(and, in this case, there\n",
    "        #    will be only one element)\n",
    "        data = entry.preprocessed_so()[0]\n",
    "        predicate = data['m_predicate']\n",
    "\n",
    "        template = te.extract_template(text, data)\n",
    "\n",
    "        # add to db\n",
    "        template_db[predicate].append(template)\n",
    "    \n",
    "# most frequent template\n",
    "# BIAS: not necessarily are the better ones -> they can be a flawed one, like the ones without m_object\n",
    "for k, templates in template_db.items():\n",
    "    \n",
    "    template_db[k] = Counter(templates).most_common(1)[0][0]\n",
    "    \n",
    "predicates_in_db = list(template_db.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(template_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{m_object} is spoken in {m_subject}.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_db['language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do I have one predicate for each predicate in test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = WebNLGCorpus.load('test_no_lex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicates_in_train_dev = set(train.mdf.m_predicate.tolist())\n",
    "predicates_in_train_dev = predicates_in_train_dev.union(set(dev.mdf.m_predicate.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicates_in_train_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There are 117 predicates in test, from 300, which don't have a template\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: how to deal with?\n",
    "predicates_in_test = set(test.mdf.m_predicate.apply(preprocess_triple_text).tolist())\n",
    "predicates_w_template = template_db.keys()\n",
    "\n",
    "\"There are {} predicates in test, from {}, which don't have a template\".format(len(predicates_in_test.difference(predicates_w_template)),\n",
    "                                                                               len(predicates_in_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "117 predicates não tiveram templates extraídos. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So, let them fall back to the nearest predicate and then to baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "def remove_stops(t):\n",
    "    \n",
    "    return ' '.join([w for w in t.split() if w not in STOP_WORDS])\n",
    "\n",
    "predicates_not_in_train_1 = set(test.mdf.m_predicate.unique()).difference(train_1.mdf.m_predicate.unique())\n",
    "predicates_not_in_train_1 = [preprocess_triple_text(p) for p in predicates_not_in_train_1]\n",
    "\n",
    "def get_nearest_predicate(predicate):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for in_db in predicates_in_db:\n",
    "        \n",
    "        no_stop_in_db = remove_stops(in_db)\n",
    "        no_stop_predicate = remove_stops(predicate)\n",
    "        \n",
    "        doc_in_db = nlp(no_stop_in_db)\n",
    "        doc_predicate = nlp(no_stop_predicate)\n",
    "        \n",
    "        sim = similarity.word2vec(doc_predicate, doc_in_db)\n",
    "        \n",
    "        similarities.append((in_db, sim))\n",
    "    \n",
    "    return max(similarities, key=lambda v: v[1])\n",
    "\n",
    "template_nearest_db = {}\n",
    "\n",
    "for m_predicate in predicates_not_in_train_1:\n",
    "    \n",
    "    logging.info(\"Processando {}\".format(m_predicate))\n",
    "    \n",
    "    nearest, sim = get_nearest_predicate(m_predicate)\n",
    "\n",
    "    template_nearest_db[m_predicate] = (nearest, sim)\n",
    "    \n",
    "    logging.info(\"Processado {}\".format(m_predicate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"Generate Sentence\")\n",
    "\n",
    "PREDICATE_NEAREST_SIMILARITY_THRESHOLD = .9\n",
    "\n",
    "# gets the nearest predicate in template_db\n",
    "# BIAS: similarity metric for predicate fallback\n",
    "# TODO: parameterize\n",
    "def get_nearest_predicate(predicate, similarity_metric):\n",
    "    \n",
    "    distances = [(in_db, similarity_metric(predicate, in_db)) for in_db in predicates_in_db]\n",
    "    \n",
    "    return max(distances, key=lambda v: v[1])\n",
    "\n",
    "# generates the sentences\n",
    "def generate_sentences(entry, similarity_metric):\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    for i, triple in enumerate(entry.preprocessed_so()):\n",
    "\n",
    "        m_predicate = triple['m_predicate']\n",
    "\n",
    "        if m_predicate in template_db:\n",
    "            \n",
    "            template = template_db[m_predicate]\n",
    "            \n",
    "            if i > 0:\n",
    "                triple['m_subject'] = ','\n",
    "            \n",
    "            text = template.format(**triple)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            nearest_predicate, sim = template_nearest_db[m_predicate]\n",
    "            \n",
    "            if sim > PREDICATE_NEAREST_SIMILARITY_THRESHOLD:\n",
    "            \n",
    "                template = template_db[nearest_predicate]\n",
    "                \n",
    "                if i > 0:\n",
    "                    triple['m_subject'] = ','\n",
    "\n",
    "                text = template.format(**triple)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                logger.warning(\"Fallback baseline for predicate %s\", m_predicate)\n",
    "                \n",
    "                text = '{m_subject} {m_predicate} {m_object}'.format(**triple)\n",
    "\n",
    "        texts.append(text)\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>mtext</th>\n",
       "      <th>m_subject</th>\n",
       "      <th>m_predicate</th>\n",
       "      <th>m_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0_419</td>\n",
       "      <td>Acta_Palaeontologica_Polonica | ISSN_number | \"0567-7920\"</td>\n",
       "      <td>Acta_Palaeontologica_Polonica</td>\n",
       "      <td>ISSN_number</td>\n",
       "      <td>\"0567-7920\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0_419</td>\n",
       "      <td>Acta_Palaeontologica_Polonica | LCCN_number | 60040714</td>\n",
       "      <td>Acta_Palaeontologica_Polonica</td>\n",
       "      <td>LCCN_number</td>\n",
       "      <td>60040714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0_419</td>\n",
       "      <td>Acta_Palaeontologica_Polonica | abbreviation | \"Acta Palaeontol. Pol.\"</td>\n",
       "      <td>Acta_Palaeontologica_Polonica</td>\n",
       "      <td>abbreviation</td>\n",
       "      <td>\"Acta Palaeontol. Pol.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx  \\\n",
       "639  0_419   \n",
       "640  0_419   \n",
       "641  0_419   \n",
       "\n",
       "                                                                      mtext  \\\n",
       "639               Acta_Palaeontologica_Polonica | ISSN_number | \"0567-7920\"   \n",
       "640                  Acta_Palaeontologica_Polonica | LCCN_number | 60040714   \n",
       "641  Acta_Palaeontologica_Polonica | abbreviation | \"Acta Palaeontol. Pol.\"   \n",
       "\n",
       "                         m_subject   m_predicate                 m_object  \n",
       "639  Acta_Palaeontologica_Polonica   ISSN_number              \"0567-7920\"  \n",
       "640  Acta_Palaeontologica_Polonica   LCCN_number                 60040714  \n",
       "641  Acta_Palaeontologica_Polonica  abbreviation  \"Acta Palaeontol. Pol.\"  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = test.sample(idx='0_419')\n",
    "\n",
    "test_sample.mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The ISSN number of Acta Palaeontologica Polonica is 0567-7920.',\n",
       " 'The LCCN number of Acta Palaeontologica Polonica is 60040714.',\n",
       " 'Acta Palaeontologica Polonica is abbreviated to Acta Palaeontol. Pol..']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.setLevel(logging.WARNING)\n",
    "generate_sentences(test_sample, similarity_metric=similarity.jaro_winkler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating texts for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(template_nearest_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.62 s, sys: 172 ms, total: 7.8 s\n",
      "Wall time: 7.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import codecs\n",
    "\n",
    "with codecs.open(output_filepath, 'w', 'utf-8') as f:\n",
    "    \n",
    "    for entry in test:\n",
    "        \n",
    "        # generates one sentence per triple\n",
    "        entry_sentences = generate_sentences(entry, similarity.jaro_winkler)\n",
    "        \n",
    "        # BIAS: aggregation\n",
    "        # TODO: how to deal with?\n",
    "        entry_text = ' '.join(entry_sentences)\n",
    "        \n",
    "        f.write(entry_text)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English language is spoken in Castle (novel).\r\n",
      "Eric Flint was born in Burbank, California.\r\n",
      "Macmillan Publishers is the parent company of Farrar, Straus and Giroux.\r\n",
      "One of John Cowper Powys notable works is A Glastonbury Romance.\r\n",
      "Soho Press is located in United States.\r\n",
      "The Secret Scripture is published by Faber and Faber.\r\n",
      "Asian Americans are an ethnic group in United States.\r\n",
      "English language is spoken in United States.\r\n",
      "Weymouth Sands is preceded by A Glastonbury Romance.\r\n",
      "The manager of A.C. Chievo Verona is Rolando Maran.\r\n"
     ]
    }
   ],
   "source": [
    "!head -100 \"$output_filepath\" | tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files creating finished for:  5 - Model - Template Based - roots_604049f5126c8e7723be2bcc42a5b3ba96fb29e8\r\n"
     ]
    }
   ],
   "source": [
    "!python ../evaluation/webnlg2017/webnlg-automatic-evaluation-v2/evaluation_v2.py --team_name \"$model_name\" --team_filepath \"$output_filepath\" --outdir \"$model_temp_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 38.75, 73.3/47.6/31.4/20.6 (BP=1.000, ratio=1.059, hyp_len=47216, ref_len=44580)\r\n"
     ]
    }
   ],
   "source": [
    "!../evaluation/webnlg2017/webnlg-baseline-master/multi-bleu.perl -lc ../evaluation/webnlg2017/webnlg-automatic-evaluation/references/gold-all-cat-reference0.lex ../evaluation/webnlg2017/webnlg-automatic-evaluation/references/gold-all-cat-reference1.lex ../evaluation/webnlg2017/webnlg-automatic-evaluation/references/gold-all-cat-reference2.lex < \"$bleu_all_cat\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
