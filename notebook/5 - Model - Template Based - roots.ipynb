{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../script/webnlg.py\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from textacy import similarity\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span(doc, node):\n",
    "    \n",
    "    return doc[node.left_edge.i: node.right_edge.i + 1]\n",
    "\n",
    "def get_left_span(doc, node):\n",
    "    \n",
    "    return doc[node.left_edge.i: node.i + 1]\n",
    "\n",
    "def get_right_span(doc, node):\n",
    "    \n",
    "    return doc[node.i: node.right_edge.i + 1]\n",
    "\n",
    "\n",
    "def as_span(doc, node):\n",
    "    \n",
    "    return doc[node.i: node.i + 1]\n",
    "\n",
    "\n",
    "def get_distances(doc, data, distance_metric):\n",
    "    \n",
    "    distances, nodes = [], []\n",
    "\n",
    "    roots = [token for token in doc if token.head == token]\n",
    "\n",
    "    for root in roots:\n",
    "        \n",
    "        root_span = get_span(doc, root)\n",
    "        root_left_span = get_left_span(doc, root)\n",
    "        root_right_span = get_right_span(doc, root)\n",
    "        root = as_span(doc, root)\n",
    "\n",
    "        # test agains the node and its subtree\n",
    "        for node in set((root, root_span, root_left_span, root_right_span)):\n",
    "            \n",
    "            nodes.append(node)\n",
    "            \n",
    "            distances_node = []\n",
    "\n",
    "            for d in data.values():\n",
    "\n",
    "                distances_node.append(distance_metric(d, node.text))\n",
    "\n",
    "            distances.append(distances_node)\n",
    "\n",
    "        roots.extend(root.lefts)\n",
    "        roots.extend(root.rights)\n",
    "        \n",
    "    return pd.DataFrame(distances, index=nodes, columns=data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_template(text, data):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    df = get_distances(doc, data, similarity.token_sort_ratio)\n",
    "    \n",
    "    text_char = list(text)\n",
    "    base = 0\n",
    "\n",
    "    for idx, span in sorted(df.idxmax().iteritems(), key=lambda v: v[1].start_char):\n",
    "        \n",
    "        text_char[base + span.start_char: base + span.end_char] = idx\n",
    "\n",
    "        base -= span.end_char - span.start_char - len(idx)\n",
    "        \n",
    "    return ''.join(text_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{subject} {predicate} up the {object} in the church\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Abelardo Vieira Mota drive up the car in the church'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Eleanor Rigby picks up the rice in the church'\n",
    "data = {'{subject}': 'Eleanor Rigby', \n",
    "        '{predicate}': 'pick up', \n",
    "        '{object}': 'rice'}\n",
    "template = generate_template(text, data)\n",
    "\n",
    "print(template)\n",
    "\n",
    "template.format(**{'subject': 'Abelardo Vieira Mota',\n",
    "          'predicate': 'drive',\n",
    "          'object': 'car'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebNLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../script/webnlg.py\n",
    "\n",
    "train = WebNLGCorpus.load('train')\n",
    "\n",
    "train_1 = train.subset(ntriples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Diagonal Street has a floor area of 1200 square metres.\n",
      "\n",
      "{'m_subject': '11_Diagonal_Street', 'm_predicate': 'floorArea', 'm_object': '1200 (square metres)'}\n",
      "\n",
      "{m_subject} has a {m_predicate} area of {m_object}.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Abelardo Vieira Mota has a house area of 100 square metres.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = train_1.sample(idx='3_14')\n",
    "\n",
    "text = s.ldf.ltext.values.tolist()[0]\n",
    "data = s.mdf[['m_subject', 'm_predicate', 'm_object']].to_dict(orient='records')[0]\n",
    "\n",
    "template = generate_template(text, data)\n",
    "# replaces m_subject -> {m_subject}\n",
    "import re\n",
    "c = re.compile('(m_subject|m_predicate|m_object)')\n",
    "template = c.sub(r'{\\1}', template)\n",
    "\n",
    "print(text)\n",
    "print()\n",
    "print(data)\n",
    "print()\n",
    "print(template)\n",
    "print()\n",
    "template.format(**{'m_subject': 'Abelardo Vieira Mota',\n",
    "          'm_predicate': 'house',\n",
    "          'm_object': '100 square metres'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
