{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../script/webnlg.py\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from textacy import similarity\n",
    "\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RootDataAlignmentModel:\n",
    "    \n",
    "    def __init__(self, similarity_metric):\n",
    "        \n",
    "        self.similarity_metric = similarity_metric\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def get_span(doc, node):\n",
    "\n",
    "        return doc[node.left_edge.i: node.right_edge.i + 1]\n",
    "    @staticmethod\n",
    "    def get_left_span(doc, node):\n",
    "\n",
    "        return doc[node.left_edge.i: node.i + 1]\n",
    "    @staticmethod\n",
    "    def get_right_span(doc, node):\n",
    "\n",
    "        return doc[node.i: node.right_edge.i + 1]\n",
    "    @staticmethod\n",
    "    def as_span(doc, node):\n",
    "\n",
    "        return doc[node.i: node.i + 1]\n",
    "\n",
    "    def get_distances(self, doc, data):\n",
    "\n",
    "        distances, nodes = [], []\n",
    "\n",
    "        roots = [token for token in doc if token.head == token]\n",
    "\n",
    "        for root in roots:\n",
    "\n",
    "            # root subtree\n",
    "            root_span = get_span(doc, root)\n",
    "            # root left subtree\n",
    "            root_left_span = get_left_span(doc, root)\n",
    "            # root right subtree\n",
    "            root_right_span = get_right_span(doc, root)\n",
    "            # root node\n",
    "            root = as_span(doc, root)\n",
    "\n",
    "            # test agains the node and its subtree\n",
    "            for node in set((root, root_span, root_left_span, root_right_span)):\n",
    "\n",
    "                nodes.append(node)\n",
    "\n",
    "                distances_node = []\n",
    "\n",
    "                for d in data.values():\n",
    "\n",
    "                    distances_node.append(self.similarity_metric(d, node.text))\n",
    "\n",
    "                distances.append(distances_node)\n",
    "\n",
    "            roots.extend(root.lefts)\n",
    "            roots.extend(root.rights)\n",
    "\n",
    "        return pd.DataFrame(distances, index=nodes, columns=data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps(x1, x2, y1, y2):\n",
    "\n",
    "    return max(0, min(x2, y2) - max(x1, y1)) > 0\n",
    "\n",
    "\n",
    "class TemplateExtractionModel:\n",
    "    \n",
    "    def __init__(self, data_alignment_model):\n",
    "    \n",
    "        self.data_alignment_model = data_alignment_model\n",
    "        \n",
    "\n",
    "    def extract_template(self, text, data):\n",
    "\n",
    "        doc = nlp(text)\n",
    "\n",
    "        df = self.data_alignment_model.get_distances(doc, data)\n",
    "\n",
    "        text_char = list(text)\n",
    "\n",
    "        # subject\n",
    "        #! BIAS: subject wins priority over distances tie\n",
    "        m_subject_span = df.m_subject.nlargest(1).index.values[0]\n",
    "\n",
    "        # replaces subject text by m_subject placeholder\n",
    "        text_char[m_subject_span.start_char: m_subject_span.end_char] = 'm_subject'\n",
    "\n",
    "        # object\n",
    "        for span in df.m_object.sort_values(ascending=False).index.values:\n",
    "\n",
    "            if overlaps(span.start_char, span.end_char,\n",
    "                        m_subject_span.start_char, m_subject_span.end_char):\n",
    "\n",
    "                continue\n",
    "\n",
    "            # tests if the object occurs after the subject >\n",
    "            #    if its the case, you have to adjust the indexes accordingly\n",
    "            if m_subject_span.start_char > span.end_char:\n",
    "\n",
    "                base = 0\n",
    "            else:\n",
    "                len_subject_text = m_subject_span.end_char - m_subject_span.start_char\n",
    "                base = len('m_subject') - len_subject_text\n",
    "\n",
    "            # replaces object text by m_object placeholder\n",
    "            text_char[base + span.start_char: base + span.end_char] = 'm_object'\n",
    "\n",
    "            break\n",
    "\n",
    "        return ''.join(text_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebNLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = WebNLGCorpus.load('train')\n",
    "\n",
    "train_1 = train.subset(ntriples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m_object is spoken in m_subject.'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = train_1.sample(idx='0_210')\n",
    "\n",
    "da = RootDataAlignmentModel(similarity.token_sort_ratio)\n",
    "te = TemplateExtractionModel(da)\n",
    "    \n",
    "te.extract_template(e.ldf.ltext.values.tolist()[0], e.mdf[['m_subject', 'm_object']].to_dict(orient='records')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>idx</th>\n",
       "      <th>lid</th>\n",
       "      <th>ltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>good</td>\n",
       "      <td>0_210</td>\n",
       "      <td>Id1</td>\n",
       "      <td>The Faroese language is spoken in Denmark.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>good</td>\n",
       "      <td>0_210</td>\n",
       "      <td>Id2</td>\n",
       "      <td>Denmark's language is Faroese.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    comment    idx  lid                                       ltext\n",
       "524    good  0_210  Id1  The Faroese language is spoken in Denmark.\n",
       "525    good  0_210  Id2              Denmark's language is Faroese."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>mtext</th>\n",
       "      <th>m_subject</th>\n",
       "      <th>m_predicate</th>\n",
       "      <th>m_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0_210</td>\n",
       "      <td>Denmark | language | Faroese_language</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>language</td>\n",
       "      <td>Faroese_language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx                                  mtext m_subject m_predicate  \\\n",
       "210  0_210  Denmark | language | Faroese_language   Denmark    language   \n",
       "\n",
       "             m_object  \n",
       "210  Faroese_language  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_subject picks up the m_object in the church\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'m_subject picks up the m_object in the church'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Eleanor Rigby picks up the rice in the church'\n",
    "data = {'m_subject': 'Eleanor Rigby', \n",
    "        'm_object': 'rice'}\n",
    "\n",
    "da = RootDataAlignmentModel(similarity.token_sort_ratio)\n",
    "te = TemplateExtractionModel(da)\n",
    "\n",
    "template = te.extract_template(text, data)\n",
    "\n",
    "print(template)\n",
    "\n",
    "template.format(**{'subject': 'Abelardo Vieira Mota',\n",
    "          'object': 'car'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# replaces m_subject -> {m_subject} to be used as a python string template\n",
    "c = re.compile('(m_subject|m_object)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 3s, sys: 8.24 s, total: 3min 11s\n",
      "Wall time: 50.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "da = RootDataAlignmentModel(similarity.token_sort_ratio)\n",
    "te = TemplateExtractionModel(da)\n",
    "\n",
    "template_db = defaultdict(list)\n",
    "\n",
    "#! BIAS: using only train_1 sentences\n",
    "# for each sentence, extracts template\n",
    "for entry in train_1:\n",
    "    \n",
    "    for text in entry.ldf.ltext.tolist():\n",
    "        # to dictionary of s, o; [0] because to_dict returns a list of dicts(and, in this case, there\n",
    "        #    will be only one element)\n",
    "        data = entry.mdf[['m_subject', 'm_object']].to_dict(orient='records')[0]\n",
    "        predicate = entry.mdf.m_predicate.values[0]\n",
    "\n",
    "        template = te.extract_template(text, data)\n",
    "\n",
    "        # puts placeholders\n",
    "        template = c.sub(r'{\\1}', template)\n",
    "\n",
    "        # add to db\n",
    "        template_db[predicate].append((entry.edf.idx.values[0], template))\n",
    "    \n",
    "# most frequent template\n",
    "for k, templates in template_db.items():\n",
    "    \n",
    "    template_db[k] = Counter([v[1] for v in templates]).most_common(1)[0][0]\n",
    "    \n",
    "predicates_in_db = list(template_db.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(template_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{m_object} is spoken in {m_subject}.'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_db['language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do I have one predicate for each predicate in test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = WebNLGCorpus.load('test_no_lex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicates_in_test = set(test.mdf.m_predicate.tolist())\n",
    "predicates_w_template = template_db.keys()\n",
    "\n",
    "len(\"There are {} predicates in test which don't have a template\".format(len(predicates_in_test ^ predicates_w_template)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So, let them fall back to the nearest predicate and then to baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.Logger('TemplateBasedModel')\n",
    "\n",
    "unwanted_separators = re.compile(r'(\\||_)')\n",
    "unwanted_multiple_empty = re.compile(r'\\s+')\n",
    "\n",
    "def preprocess_triple(s):\n",
    "    \n",
    "    sep_changed = unwanted_separators.sub(' ', s)\n",
    "    mult_empty_removed = unwanted_multiple_empty.sub(' ', sep_changed)\n",
    "    \n",
    "    return mult_empty_removed.replace('\"', '')\n",
    "\n",
    "def get_nearest_predicate(predicate):\n",
    "    \n",
    "    distances = [(in_db, similarity.jaro_winkler(predicate, in_db)) for in_db in predicates_in_db]\n",
    "    \n",
    "    return min(distances, key=lambda v: v[1])\n",
    "\n",
    "\n",
    "def generate_sentences(entry):\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    for i, triple in entry.mdf.iterrows():\n",
    "\n",
    "        m_predicate = triple.m_predicate\n",
    "\n",
    "        if m_predicate in template_db:\n",
    "            \n",
    "            template = template_db[m_predicate]\n",
    "\n",
    "            preprocessed_triple = triple[['m_subject', 'm_object']].apply(preprocess_triple)\n",
    "\n",
    "            text = template.format(**preprocessed_triple.to_dict())\n",
    "\n",
    "        else:\n",
    "            \n",
    "            nearest_predicate, similarity = get_nearest_predicate(m_predicate)\n",
    "            \n",
    "            if similarity > .4:\n",
    "                \n",
    "                logger.warning(\"Fallback nearest predicate for predicate %s\", m_predicate)\n",
    "                \n",
    "                template = template_db[nearest_predicate]\n",
    "\n",
    "                preprocessed_triple = triple[['m_subject', 'm_object']].apply(preprocess_triple)\n",
    "\n",
    "                text = template.format(**preprocessed_triple.to_dict())\n",
    "                \n",
    "            else:\n",
    "                \n",
    "               # logger.warning(\"Fallback baseline for predicate %s\", m_predicate)\n",
    "\n",
    "                text = preprocess_triple(triple.mtext)\n",
    "\n",
    "        texts.append(text)\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>mtext</th>\n",
       "      <th>m_subject</th>\n",
       "      <th>m_predicate</th>\n",
       "      <th>m_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0_419</td>\n",
       "      <td>Acta_Palaeontologica_Polonica | ISSN_number | \"0567-7920\"</td>\n",
       "      <td>Acta_Palaeontologica_Polonica</td>\n",
       "      <td>ISSN_number</td>\n",
       "      <td>\"0567-7920\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0_419</td>\n",
       "      <td>Acta_Palaeontologica_Polonica | LCCN_number | 60040714</td>\n",
       "      <td>Acta_Palaeontologica_Polonica</td>\n",
       "      <td>LCCN_number</td>\n",
       "      <td>60040714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0_419</td>\n",
       "      <td>Acta_Palaeontologica_Polonica | abbreviation | \"Acta Palaeontol. Pol.\"</td>\n",
       "      <td>Acta_Palaeontologica_Polonica</td>\n",
       "      <td>abbreviation</td>\n",
       "      <td>\"Acta Palaeontol. Pol.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx  \\\n",
       "639  0_419   \n",
       "640  0_419   \n",
       "641  0_419   \n",
       "\n",
       "                                                                      mtext  \\\n",
       "639               Acta_Palaeontologica_Polonica | ISSN_number | \"0567-7920\"   \n",
       "640                  Acta_Palaeontologica_Polonica | LCCN_number | 60040714   \n",
       "641  Acta_Palaeontologica_Polonica | abbreviation | \"Acta Palaeontol. Pol.\"   \n",
       "\n",
       "                         m_subject   m_predicate                 m_object  \n",
       "639  Acta_Palaeontologica_Polonica   ISSN_number              \"0567-7920\"  \n",
       "640  Acta_Palaeontologica_Polonica   LCCN_number                 60040714  \n",
       "641  Acta_Palaeontologica_Polonica  abbreviation  \"Acta Palaeontol. Pol.\"  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = test.sample(idx='0_419')\n",
    "\n",
    "test_sample.mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The ISSN number of Acta Palaeontologica Polonica is 0567-7920.',\n",
       " 'The LCCN number of Acta Palaeontologica Polonica is 60040714.',\n",
       " 'Acta Palaeontologica Polonica is abbreviated Acta Palaeontol. Pol.. Pol.']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.setLevel(logging.WARN)\n",
    "generate_sentences(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating texts for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "with codecs.open('models/template_based/output.txt', 'w', 'utf-8') as f:\n",
    "    \n",
    "    for entry in test:\n",
    "        \n",
    "        entry_sentences = generate_sentences(entry)\n",
    "        \n",
    "        entry_text = ' '.join(entry_sentences)\n",
    "        \n",
    "        f.write(entry_text)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English language is spoken in Castle (novel).\r\n",
      "Eric Flint was born in Burbank, California.\r\n",
      "Farrar, Straus and Giroux is the parent company of the Macmillan Publishers Press.\r\n",
      "One of John Cowper Powys notable works is Oliver A Glastonbury Romance.\r\n",
      "Soho Press is located in United States.\r\n",
      "Faber and Faber is the publisher of The Secret Scripture.\r\n",
      "Asian Americans are an ethnic group in the United United States.\r\n",
      "English language is spoken in United States.\r\n",
      "Weymouth Sands by 1634: The A Glastonbury Romance Affair.\r\n",
      "Rolando Maran manages A.C. Chievo Verona.\r\n"
     ]
    }
   ],
   "source": [
    "!head -100 models/template_based/output.txt | tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files creating finished for:  template_based\r\n"
     ]
    }
   ],
   "source": [
    "!python ../evaluation/webnlg2017/webnlg-automatic-evaluation-v2/evaluation_v2.py --team_name template_based --team_filepath models/template_based/output.txt --outdir models/template_based/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 37.01, 65.0/44.8/30.7/21.0 (BP=1.000, ratio=1.156, hyp_len=52216, ref_len=45189)\r\n"
     ]
    }
   ],
   "source": [
    "!../evaluation/webnlg2017/webnlg-baseline-master/multi-bleu.perl -lc ../evaluation/webnlg2017/webnlg-automatic-evaluation/references/gold-all-cat-reference0.lex ../evaluation/webnlg2017/webnlg-automatic-evaluation/references/gold-all-cat-reference1.lex ../evaluation/webnlg2017/webnlg-automatic-evaluation/references/gold-all-cat-reference2.lex < models/template_based/template_based_all-cat.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
