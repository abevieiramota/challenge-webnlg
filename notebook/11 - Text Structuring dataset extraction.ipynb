{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.sys.path.insert(0, '../script')\n",
    "from webnlg import WebNLGCorpus\n",
    "from textacy import extract, spacy_utils, preprocess\n",
    "from textacy import similarity\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg', disable=['ner'])\n",
    "\n",
    "# bug? https://github.com/explosion/spaCy/issues/1574#issuecomment-391732372\n",
    "for word in nlp.Defaults.stop_words:\n",
    "    for w in (word, word[0].upper() + word[1:], word.upper()):\n",
    "        lex = nlp.vocab[word]\n",
    "        lex.is_stop = True\n",
    "\n",
    "train = WebNLGCorpus.load('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "* LOG AND TRACK CASES WHERE THE ALGORITHM WASN'T ABLE TO DELEXICALIZE ALL PREDICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 42 Âµs\n",
      "Parser   : 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import re \n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "def test_if_overlaps_with(tested_span, to_test_span=None):\n",
    "    \n",
    "    # doesn't overlap with None\n",
    "    if not to_test_span:\n",
    "        return False\n",
    "    \n",
    "    # tests if the spans have overlap\n",
    "    return tested_span.start_char <= to_test_span.end_char and to_test_span.start_char <= tested_span.end_char\n",
    "\n",
    "translate_punct_to_none = str.maketrans({k: ' ' for k in string.punctuation})\n",
    "\n",
    "def preprocess_text_to_compare(s):\n",
    "    \n",
    "    return s.translate(translate_punct_to_none)\n",
    "    \n",
    "\n",
    "# regex to replace sequences of dots to a single dot -> \n",
    "#    there are cases of, I think, typos of two dots(OMG I've just thought that maybe it was a case of <abbreviature, final dot>)\n",
    "c_dot = re.compile(r'\\.{1,}')\n",
    "# regex to extract PREDICATE tags\n",
    "#    they are put in the format PREDICATE-$predicate_string$\n",
    "#    and I need to find them and extract the predicate_string part\n",
    "c_predicate = re.compile(r'PREDICATE-\\$(.*?)\\$')\n",
    "\n",
    "c_remove_lowercase = re.compile(r'[^A-Z]')\n",
    "\n",
    "def extract_from_entry(entry, ngram_lim=(1, 12), threshold_full=0.8, threshold_abbrev=0.5):\n",
    "    \n",
    "    positions = []\n",
    "\n",
    "    # for each lexicalization\n",
    "    for text in entry.lexes():\n",
    "        # creates an array of chars from the lexicalization\n",
    "        #    used to replace objects strings by tags\n",
    "        #    because, in Python, str is immutable\n",
    "        text_char = list(text)\n",
    "\n",
    "        # creates a doc of the lexicalization\n",
    "        doc = nlp(c_dot.sub('.', text))\n",
    "\n",
    "        ngrams = []\n",
    "        for n in range(*ngram_lim):\n",
    "            ngrams.extend(extract.ngrams(doc, n, filter_punct=False, filter_stops=False, filter_nums=False))\n",
    "\n",
    "        sims = []\n",
    "\n",
    "        for ngram in ngrams:\n",
    "            \n",
    "            ngram_preprocessed = preprocess_text_to_compare(ngram.text)\n",
    "\n",
    "            for triple in entry.get_data():\n",
    "                \n",
    "                object_preprocessed = preprocess_text_to_compare(triple['object'])\n",
    "                object_abbrev_preprocessed = c_remove_lowercase.sub('', object_preprocessed)\n",
    "\n",
    "                sims.append({'ngram': ngram,\n",
    "                             'predicate': triple['predicate'],\n",
    "                             'object': triple['object'],\n",
    "                             'sim': similarity.levenshtein(ngram_preprocessed, object_preprocessed),\n",
    "                             'sim_abbrev': similarity.levenshtein(ngram_preprocessed, object_abbrev_preprocessed)})\n",
    "\n",
    "        df = pd.DataFrame(sims)\n",
    "        \n",
    "        choosen_ngram = None\n",
    "        choosen_rows = []\n",
    "        \n",
    "        predicates_objects = [(data['predicate'], len(data['object'])) for data in entry.get_data()]\n",
    "        sorted_predicates = [v[0] for v in sorted(predicates_objects, key=lambda v: v[1], reverse=True)]\n",
    "        \n",
    "        g_ = df\n",
    "        \n",
    "        for predicate in sorted_predicates:\n",
    "            \n",
    "            # removes overlaps\n",
    "            g_ = g_[~g_.ngram.apply(lambda n: test_if_overlaps_with(n, choosen_ngram))]\n",
    "            \n",
    "            choosen_row = g_[g_.predicate == predicate].nlargest(1, 'sim')\n",
    "            \n",
    "            if choosen_row.sim.values[0] < threshold_full:\n",
    "                \n",
    "                choosen_row = g_[g_.predicate == predicate].nlargest(1, 'sim_abbrev')\n",
    "                \n",
    "                if choosen_row.sim_abbrev.values[0] < threshold_abbrev:\n",
    "                    choosen_ngram = None\n",
    "                    continue\n",
    "\n",
    "            choosen_ngram = choosen_row.ngram.values[0]\n",
    "            choosen_rows.append(choosen_row.index.values[0])\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "        g = df.loc[choosen_rows, :]\n",
    "        \n",
    "        g['end_char'] = g.ngram.apply(lambda x: x.end_char)\n",
    "        \n",
    "        for idx, row in g.sort_values('end_char', ascending=False).iterrows():\n",
    "\n",
    "            text_char[row['ngram'].start_char: row['ngram'].end_char] = f'PREDICATE-${row[\"predicate\"]}$'\n",
    "\n",
    "        final = ''.join(text_char)\n",
    "        \n",
    "        predicate_position = []\n",
    "\n",
    "        for i, sent in enumerate(nlp(final).sents):\n",
    "\n",
    "            predicate_position.append(c_predicate.findall(sent.text))\n",
    "\n",
    "        positions.append((final, predicate_position))\n",
    "        \n",
    "    return positions\n",
    "    \n",
    "\n",
    "result = []\n",
    "\n",
    "#for entry in tqdm(list(train)):\n",
    "#    result.append(extract_from_entry(entry))\n",
    "\n",
    "#with open('alignment3', 'bw') as f:\n",
    "#   pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Triple info: category=WrittenWork eid=Id239\n",
       "\n",
       "\tModified triples:\n",
       "\n",
       "United_States | leaderTitle | President_of_the_United_States\n",
       "1634:_The_Ram_Rebellion | country | United_States\n",
       "United_States | ethnicGroup | Asian_Americans\n",
       "\n",
       "\n",
       "\tLexicalizations:\n",
       "\n",
       "1634 The Ram Rebellion comes from the United States where one of the ethnic groups is Asian Americans and the leader of the country is called the President.\n",
       "1634 The Ram Rebellion comes from the United States, where the title of the leader is the President and where there are many Asian Americans.\n",
       "1634: The Ram Rebellion was written in the US; which is home to many Asian Americans."
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list(train)\n",
    "X[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1634 The Ram Rebellion comes PREDICATE-$leaderTitle$ where one of the ethnic groups is PREDICATE-$ethnicGroup$ and the leader of the country is called the President.',\n",
       "  [['leaderTitle', 'ethnicGroup']]),\n",
       " ('1634 The Ram Rebellion comes PREDICATE-$leaderTitle$, where the title of the leader is the President and where there are many PREDICATE-$ethnicGroup$.',\n",
       "  [['leaderTitle', 'ethnicGroup']]),\n",
       " ('1634: The Ram Rebellion was written in the PREDICATE-$leaderTitle$; which is home to many PREDICATE-$ethnicGroup$.',\n",
       "  [['leaderTitle', 'ethnicGroup']])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_from_entry(X[-10], threshold_full=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -500\n",
    "# Gary_Cohn_(comics) -> The comic character Bolt was created by Paris Cullins and Gary Cohn, the former being a United States national.\n",
    "# -600\n",
    "# Brazil -> Brazilian-based"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
