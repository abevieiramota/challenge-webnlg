{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../script/webnlg.py\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = WebNLGCorpus(dataset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Left Ecology Freedom are the leading party in Gubbio.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = train.sample(idx='6_164')\n",
    "e.lexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'m_object': 'Left_Ecology_Freedom',\n",
       "  'm_predicate': 'leaderParty',\n",
       "  'm_subject': 'Gubbio'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.triples(kind='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def split(spo):\n",
    "    \n",
    "    return spo.split(' ')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(spo):\n",
    "    \n",
    "    return ' '.join((lemmatizer.lemmatize(spo_) for spo_ in split(spo)))\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer_ = 'lancaster'\n",
    "\n",
    "if stemmer_ == 'lancaster':\n",
    "    stemmer = LancasterStemmer()\n",
    "elif stemmer == 'porter':\n",
    "    stemmer = PorterStemmer()\n",
    "else:\n",
    "    stemmer = SnowballStemmer()\n",
    "\n",
    "def stem(spo):\n",
    "    \n",
    "    return ' '.join((stemmer.stem(spo_) for spo_ in split(spo)))\n",
    "\n",
    "c_detect_camelcase = re.compile(r'(?<=[a-z])([A-Z])')\n",
    "def split_by_camelcase(spo):\n",
    "    \n",
    "    return c_detect_camelcase.sub(r' \\1', spo)\n",
    "\n",
    "c_chars_to_remove = re.compile(r'[_]')\n",
    "def remove_unwanted_char(spo):\n",
    "    \n",
    "    return c_chars_to_remove.sub(' ', spo)\n",
    "\n",
    "def to_lower(spo):\n",
    "    \n",
    "    return spo.lower()\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "spo_pipeline = [split_by_camelcase, remove_unwanted_char, to_lower, stem]\n",
    "def preprocess_spo(spo):\n",
    "    \n",
    "    return reduce(lambda v, f: f(v), spo_pipeline, spo)\n",
    "    \n",
    "def preprocess_triple(triple):\n",
    "\n",
    "    return {k:preprocess_spo(v) for k, v in triple.items()}    \n",
    "\n",
    "lexe_pipeline = [to_lower, stem]\n",
    "def preprocess_lexe(lexe):\n",
    "    \n",
    "    return reduce(lambda v, f: f(v), lexe_pipeline, lexe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sop(m):\n",
    "    \n",
    "    return \"<{}>\".format(next((k for k, v in m.groupdict().items() if v)))\n",
    "\n",
    "def simple_align(triple, lexe):\n",
    "    \n",
    "    preprocessed_triple = preprocess_triple(triple)\n",
    "    \n",
    "    preprocessed_lexe = preprocess_lexe(lexe)\n",
    "    \n",
    "    regex = '((?P<subject>{m_subject})|(?P<predicate>{m_predicate})|(?P<object>{m_object}))'.format(**preprocessed_triple)\n",
    "    \n",
    "    return re.compile(regex).sub(replace_sop, preprocessed_lexe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the <object> ar the <predicate> in <subject>.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = simple_align(e.triples(kind='dict')[0], e.lexes()[0])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_spo = re.compile(r'((?P<object><object>)|(?P<predicate><predicate>)|(?P<subject><subject>))')\n",
    "\n",
    "def count_spo(s):\n",
    "    \n",
    "    return [t[0] for t in c_search_spo.findall(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the character, <subject>es, was <predicate> by <object>.',\n",
       " ['<subject>', '<predicate>', '<object>'],\n",
       " {'m_object': 'Len_Wein', 'm_predicate': 'creator', 'm_subject': 'Aurakles'})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = train.sample()\n",
    "c = simple_align(e.triples(kind='dict')[0], e.lexes()[0])\n",
    "c, count_spo(c), e.triples()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<subject> is a <object>.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': None, 'predicate': None, 'subject': '<subject>'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_search_spo.match(c).groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<subject>', '', '', '<subject>'),\n",
       " ('<object>', '<object>', '', ''),\n",
       " ('<predicate>', '', '<predicate>', ''),\n",
       " ('<subject>', '', '', '<subject>')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_search_spo.findall('<subject> <object> <predicate> <subject>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
